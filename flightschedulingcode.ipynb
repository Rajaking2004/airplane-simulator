{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugBeZeLgtCSS"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Step 1: Upload the file from your device\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages with new additions for advanced models\n",
        "!pip install -q ortools lightgbm networkx sentence-transformers\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Scikit-learn and LightGBM for predictive models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (mean_absolute_error,\n",
        "                             mean_squared_error,\n",
        "                             r2_score,\n",
        "                             median_absolute_error,\n",
        "                             explained_variance_score,\n",
        "                             accuracy_score)\n",
        "\n",
        "# Try importing optional packages with fallbacks\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    LIGHTGBM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: LightGBM not available. Using RandomForest only.\")\n",
        "    LIGHTGBM_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import networkx as nx\n",
        "    NETWORKX_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: NetworkX not available. Graph analysis will be skipped.\")\n",
        "    NETWORKX_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from ortools.sat.python import cp_model\n",
        "    ORTOOLS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: OR-Tools not available. Schedule optimization will be skipped.\")\n",
        "    ORTOOLS_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer, util\n",
        "    SENTENCE_TRANSFORMERS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: SentenceTransformers not available. NLP features will be limited.\")\n",
        "    SENTENCE_TRANSFORMERS_AVAILABLE = False\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "2CBIVrxUtJ1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 1. ENHANCED DATA PROCESSOR\n",
        "# ===============================================================================\n",
        "\n",
        "class FlightDataProcessor:\n",
        "    \"\"\"Enhanced data processor with runway and gate modeling\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.encoders = {}\n",
        "        self.scalers = {}\n",
        "        self.runway_config = self._initialize_runway_config()\n",
        "        self.gate_config = self._initialize_gate_config()\n",
        "\n",
        "    def _initialize_runway_config(self):\n",
        "        \"\"\"Initialize runway configuration\"\"\"\n",
        "        return {\n",
        "            'runways': ['RW09L', 'RW09R', 'RW27L', 'RW27R'],\n",
        "            'capacity_per_hour': {'RW09L': 30, 'RW09R': 30, 'RW27L': 28, 'RW27R': 28},\n",
        "            'separation_matrix': {\n",
        "                ('A320', 'A320'): 90, ('A320', 'B777'): 120,\n",
        "                ('B777', 'A320'): 150, ('B777', 'B777'): 120,\n",
        "                ('default', 'default'): 90\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _initialize_gate_config(self):\n",
        "        \"\"\"Initialize gate configuration\"\"\"\n",
        "        return {\n",
        "            'terminal_1': [f'1A{i:02d}' for i in range(1, 21)],\n",
        "            'terminal_2': [f'2B{i:02d}' for i in range(1, 16)],\n",
        "            'terminal_3': [f'3C{i:02d}' for i in range(1, 31)]\n",
        "        }\n",
        "\n",
        "    def generate_synthetic_data(self, n_flights=1000):\n",
        "        \"\"\"Generate comprehensive synthetic flight data\"\"\"\n",
        "        print(\"üîß Generating synthetic flight data...\")\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Flight parameters\n",
        "        airlines = ['6E', 'AI', 'SG', 'UK', 'G8', 'I5', '9W', 'S2']\n",
        "        destinations = ['DEL', 'BOM', 'BLR', 'MAA', 'HYD', 'CCU', 'AMD', 'COK', 'GOI', 'PNQ', 'JAI', 'IXC']\n",
        "        aircraft_types = ['A320', 'A321', 'B737', 'B777', 'A330', 'ATR72', 'CRJ200']\n",
        "\n",
        "        data = []\n",
        "        base_date = datetime.now().replace(hour=6, minute=0, second=0, microsecond=0)\n",
        "\n",
        "        for i in range(n_flights):\n",
        "            # Flight details\n",
        "            airline = np.random.choice(airlines)\n",
        "            flight_num = f\"{airline}{np.random.randint(100, 9999)}\"\n",
        "            destination = np.random.choice(destinations)\n",
        "            aircraft_type = np.random.choice(aircraft_types)\n",
        "            aircraft = f\"VT-A{np.random.randint(100, 120)}\" # Fewer aircraft for more connections\n",
        "\n",
        "            # Time scheduling (6 AM to 11 PM)\n",
        "            hours_offset = np.random.exponential(2) * 8  # Concentrate in early hours\n",
        "            std_offset = min(hours_offset * 60, 17 * 60)  # Cap at 11 PM\n",
        "            std = base_date + timedelta(minutes=std_offset)\n",
        "\n",
        "            # Realistic delay modeling\n",
        "            dep_delay = max(0, np.random.gamma(2, 8) - 10)  # Skewed distribution\n",
        "\n",
        "            # Arrival delay correlated with departure delay\n",
        "            propagation_factor = np.random.uniform(0.6, 1.2)\n",
        "            weather_impact = np.random.normal(0, 5)\n",
        "            arr_delay = max(0, dep_delay * propagation_factor + weather_impact)  # Ensure non-negative\n",
        "\n",
        "            # Flight duration based on destination\n",
        "            duration_map = {\n",
        "                'DEL': 120, 'BOM': 150, 'BLR': 90, 'MAA': 60, 'HYD': 75,\n",
        "                'CCU': 180, 'AMD': 135, 'COK': 75, 'GOI': 105, 'PNQ': 120,\n",
        "                'JAI': 105, 'IXC': 165\n",
        "            }\n",
        "            base_duration = duration_map.get(destination, 120)\n",
        "            flight_duration = max(30, base_duration + np.random.normal(0, 15))  # Ensure minimum duration\n",
        "\n",
        "            # Calculate times\n",
        "            sta = std + timedelta(minutes=flight_duration)\n",
        "\n",
        "            data.append({\n",
        "                'flight_id': f\"{flight_num}-{i}\",\n",
        "                'flight_number': flight_num,\n",
        "                'airline': airline,\n",
        "                'std': std,\n",
        "                'sta': sta,\n",
        "                'to': destination,\n",
        "                'aircraft': aircraft,\n",
        "                'aircraft_type': aircraft_type,\n",
        "                'dep_delay': dep_delay,\n",
        "                'arr_delay': arr_delay,\n",
        "                'flight_duration': flight_duration\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(data).sort_values('std').reset_index(drop=True)\n",
        "\n",
        "    def engineer_features(self, df):\n",
        "        \"\"\"Comprehensive feature engineering\"\"\"\n",
        "        print(\"‚öôÔ∏è Engineering features...\")\n",
        "        df = df.copy()\n",
        "        df['scheduled_hour'] = df['std'].dt.hour\n",
        "        df['day_of_week'] = df['std'].dt.dayofweek\n",
        "        df['flight_time_minutes'] = df['flight_duration']\n",
        "\n",
        "        # Calculate hourly flight count\n",
        "        hourly_counts = df.groupby('scheduled_hour').size().reset_index(name='hourly_flight_count')\n",
        "        df = df.merge(hourly_counts, on='scheduled_hour', how='left')\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "ht1vtJ88tY17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 2. FLIGHT OPERATIONS SIMULATOR (INTEGRATED)\n",
        "# ===============================================================================\n",
        "class FlightSimulator:\n",
        "    \"\"\"Flight operations simulator\"\"\"\n",
        "\n",
        "    def __init__(self, runway_config, gate_config):\n",
        "        self.runway_config = runway_config\n",
        "        self.gate_config = gate_config\n",
        "\n",
        "    def simulate_day(self, flights_df):\n",
        "        \"\"\"Simulate flight operations under different scenarios\"\"\"\n",
        "        print(\"üé≠ Running flight simulation...\")\n",
        "        scenarios = [\n",
        "            {\"name\": \"normal\", \"delay_factor\": 1.0, \"congestion_factor\": 1.0},\n",
        "            {\"name\": \"bad_weather\", \"delay_factor\": 1.8, \"congestion_factor\": 1.3},\n",
        "            {\"name\": \"peak_congestion\", \"delay_factor\": 1.4, \"congestion_factor\": 2.0}\n",
        "        ]\n",
        "        results = {}\n",
        "\n",
        "        for scenario in scenarios:\n",
        "            simulated_delays = (flights_df['arr_delay'] * scenario['delay_factor']) + \\\n",
        "                                (flights_df['hourly_flight_count'].fillna(0) - 10).clip(lower=0) * scenario['congestion_factor']\n",
        "\n",
        "            results[scenario['name']] = {\n",
        "                'avg_delay': simulated_delays.mean(),\n",
        "                'max_queue_length': (flights_df['hourly_flight_count'].fillna(0) - 15).clip(lower=0).max(),\n",
        "                'flights_processed': len(flights_df),\n",
        "                'total_delay': simulated_delays.sum()\n",
        "            }\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "F8-f9BVgtjmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 3. MODEL EVALUATION FUNCTIONS (ENHANCED WITH NEW METRICS)\n",
        "# ===============================================================================\n",
        "\n",
        "def predict_with_model(model, X_test):\n",
        "    \"\"\"Step 1: Generate predictions for a given model.\"\"\"\n",
        "    try:\n",
        "        if hasattr(model, 'predict'):\n",
        "            return model.predict(X_test)\n",
        "        else:\n",
        "            print(f\"Warning: Model {type(model).__name__} lacks a .predict() method.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction: {e}\")\n",
        "        return None\n",
        "\n",
        "def calculate_regression_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Step 2: Calculate standard and advanced regression metrics, including operational metrics.\n",
        "    \"\"\"\n",
        "    if y_pred is None or len(y_pred) == 0:\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        # Ensure arrays are properly shaped and contain no NaN values\n",
        "        y_true = np.array(y_true).flatten()\n",
        "        y_pred = np.array(y_pred).flatten()\n",
        "\n",
        "        # Remove any NaN or infinite values\n",
        "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
        "        if not np.any(mask):\n",
        "            return {}\n",
        "\n",
        "        y_true = y_true[mask]\n",
        "        y_pred = y_pred[mask]\n",
        "\n",
        "        metrics = {\n",
        "            'MAE': mean_absolute_error(y_true, y_pred),\n",
        "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "            'R2_Score': r2_score(y_true, y_pred),\n",
        "            'MedAE': median_absolute_error(y_true, y_pred),\n",
        "            'Explained_Variance': explained_variance_score(y_true, y_pred)\n",
        "        }\n",
        "\n",
        "        # --- NEW: Operational (Business) Metrics ---\n",
        "        y_true_on_time = (y_true <= 15)\n",
        "        y_pred_on_time = (y_pred <= 15)\n",
        "        metrics['On_Time_Accuracy'] = accuracy_score(y_true_on_time, y_pred_on_time)\n",
        "\n",
        "        y_true_severe = (y_true > 60)\n",
        "        y_pred_severe = (y_pred > 60)\n",
        "        metrics['Severe_Delay_Accuracy'] = accuracy_score(y_true_severe, y_pred_severe)\n",
        "\n",
        "        return metrics\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating metrics: {e}\")\n",
        "        return {}\n",
        "\n",
        "def generate_evaluation_report(model_name, metrics):\n",
        "    \"\"\"\n",
        "    Step 3: Print a formatted report for a model's performance with new metrics.\n",
        "    \"\"\"\n",
        "    if not metrics:\n",
        "        print(f\"‚ùå {model_name}: No metrics available\")\n",
        "        return\n",
        "\n",
        "    print(f\"üìà {model_name.replace('_', ' ').title()} Results:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"Statistical Performance:\")\n",
        "    print(f\"  - Mean Absolute Error (MAE):      {metrics.get('MAE', 0):.2f} minutes\")\n",
        "    print(f\"  - Median Absolute Error (MedAE):    {metrics.get('MedAE', 0):.2f} minutes  (More robust to outliers)\")\n",
        "    print(f\"  - Root Mean Squared Error (RMSE):   {metrics.get('RMSE', 0):.2f} minutes  (Penalizes large errors)\")\n",
        "    print(f\"  - R-squared (R¬≤):                 {metrics.get('R2_Score', 0):.3f}\")\n",
        "    print(f\"  - Explained Variance:             {metrics.get('Explained_Variance', 0):.3f}\")\n",
        "    print(\"\\nOperational Performance:\")\n",
        "    print(f\"  - On-Time (<=15min) Accuracy:     {metrics.get('On_Time_Accuracy', 0) * 100:.2f}%\")\n",
        "    print(f\"  - Severe Delay (>60min) Accuracy: {metrics.get('Severe_Delay_Accuracy', 0) * 100:.2f}%\\n\")\n",
        "\n",
        "def evaluate_and_report_models(models, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Main Orchestrator: Evaluates a dictionary of models and reports their performance.\n",
        "    \"\"\"\n",
        "    all_results = {}\n",
        "    print(\"\\nüìä Evaluating Model Performance:\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        y_pred = predict_with_model(model, X_test)\n",
        "        metrics = calculate_regression_metrics(y_test, y_pred)\n",
        "        all_results[name] = metrics\n",
        "        generate_evaluation_report(name, metrics)\n",
        "\n",
        "    # Create results DataFrame only if we have results\n",
        "    if all_results:\n",
        "        results_df = pd.DataFrame(all_results).T\n",
        "        print(\"üìä Evaluation Summary DataFrame:\")\n",
        "        print(results_df.round(3))\n",
        "        return all_results, results_df\n",
        "    else:\n",
        "        return {}, pd.DataFrame()"
      ],
      "metadata": {
        "id": "sBspmJtDto06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 4. ADVANCED ML PREDICTOR (INTEGRATED WITH NEW EVALUATOR FUNCTIONS)\n",
        "# ===============================================================================\n",
        "\n",
        "class AdvancedFlightPredictor:\n",
        "    \"\"\"Enhanced ML predictor with ensemble methods\"\"\"\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.encoders = {}\n",
        "        self.feature_columns = []\n",
        "\n",
        "    def prepare_features(self, df):\n",
        "        \"\"\"Prepare features for modeling\"\"\"\n",
        "        potential_features = [\n",
        "            'dep_delay', 'airline', 'to', 'aircraft_type', 'flight_time_minutes',\n",
        "            'scheduled_hour', 'day_of_week', 'hourly_flight_count'\n",
        "        ]\n",
        "        # Ensure only columns present in the dataframe are used\n",
        "        self.feature_columns = [col for col in potential_features if col in df.columns]\n",
        "        return self.feature_columns\n",
        "\n",
        "    def train_ensemble_models(self, df):\n",
        "        \"\"\"Train Random Forest and LightGBM models\"\"\"\n",
        "        print(\"ü§ñ Training ensemble ML models...\")\n",
        "\n",
        "        try:\n",
        "            features = self.prepare_features(df)\n",
        "            if not features:\n",
        "                print(\"‚ùå No valid features found for training\")\n",
        "                return {}\n",
        "\n",
        "            # Check if target column exists\n",
        "            if 'arr_delay' not in df.columns:\n",
        "                print(\"‚ùå Target column 'arr_delay' not found\")\n",
        "                return {}\n",
        "\n",
        "            model_df = df[features + ['arr_delay']].copy().dropna()\n",
        "\n",
        "            if len(model_df) < 10:\n",
        "                print(\"‚ùå Insufficient data for training\")\n",
        "                return {}\n",
        "\n",
        "            # Encode categorical features\n",
        "            categorical_features = ['airline', 'to', 'aircraft_type']\n",
        "            for col in categorical_features:\n",
        "                if col in model_df.columns:\n",
        "                    le = LabelEncoder()\n",
        "                    model_df[col] = le.fit_transform(model_df[col].astype(str))\n",
        "                    self.encoders[col] = le\n",
        "\n",
        "            X = model_df[features]\n",
        "            y = model_df['arr_delay']\n",
        "\n",
        "            # Ensure we have valid data\n",
        "            if X.empty or y.empty:\n",
        "                print(\"‚ùå No valid data after preprocessing\")\n",
        "                return {}\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Train Random Forest\n",
        "            print(\"Training Random Forest...\")\n",
        "            rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
        "            rf_model.fit(X_train, y_train)\n",
        "            self.models['random_forest'] = rf_model\n",
        "\n",
        "            # Train LightGBM if available\n",
        "            if LIGHTGBM_AVAILABLE:\n",
        "                print(\"Training LightGBM...\")\n",
        "                lgbm_model = lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
        "                lgbm_model.fit(X_train, y_train)\n",
        "                self.models['lightgbm'] = lgbm_model\n",
        "\n",
        "            # Evaluate models\n",
        "            if self.models:\n",
        "                evaluate_and_report_models(self.models, X_test, y_test)\n",
        "\n",
        "            return self.models\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error during model training: {e}\")\n",
        "            return {}\n"
      ],
      "metadata": {
        "id": "hBCK378YtxaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 5. GRAPH-BASED CASCADING IMPACT ANALYZER (NEW & ADVANCED)\n",
        "# ===============================================================================\n",
        "class GraphImpactAnalyzer:\n",
        "    \"\"\"\n",
        "    Models the airport as a network to find flights with the highest\n",
        "    cascading delay potential using graph theory (PageRank).\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "        if NETWORKX_AVAILABLE:\n",
        "            self.graph = nx.DiGraph()\n",
        "        else:\n",
        "            self.graph = None\n",
        "\n",
        "    def build_flight_network(self, min_turnaround_time=45):\n",
        "        if not NETWORKX_AVAILABLE:\n",
        "            print(\"‚ùå NetworkX not available. Skipping network analysis.\")\n",
        "            return\n",
        "\n",
        "        print(\"üï∏Ô∏è Building flight network graph...\")\n",
        "\n",
        "        try:\n",
        "            # Add nodes\n",
        "            for index, flight in self.df.iterrows():\n",
        "                self.graph.add_node(flight['flight_id'], hour=flight['std'].hour)\n",
        "\n",
        "            # Add edges based on aircraft turnaround times\n",
        "            for aircraft_reg, group in self.df.groupby('aircraft'):\n",
        "                flights = group.sort_values('std').to_dict('records')\n",
        "                for i in range(len(flights) - 1):\n",
        "                    current_flight = flights[i]\n",
        "                    next_flight = flights[i+1]\n",
        "\n",
        "                    # Calculate turnaround time\n",
        "                    turnaround = (next_flight['std'] - current_flight['sta']).total_seconds() / 60\n",
        "\n",
        "                    # Add edge if there's a reasonable connection\n",
        "                    if 0 < turnaround < min_turnaround_time * 2:\n",
        "                        weight = 1/turnaround if turnaround > 0 else 100\n",
        "                        self.graph.add_edge(current_flight['flight_id'],\n",
        "                                            next_flight['flight_id'],\n",
        "                                            weight=weight)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error building flight network: {e}\")\n",
        "\n",
        "    def find_top_disruptors(self, top_n=10):\n",
        "        \"\"\"\n",
        "        Runs the PageRank algorithm to identify the most influential flights.\n",
        "        \"\"\"\n",
        "        if not NETWORKX_AVAILABLE:\n",
        "            print(\"‚ùå NetworkX not available. Using simple heuristic for impact analysis.\")\n",
        "            # Simple fallback: use combination of early departure time and frequency\n",
        "            self.df['impact_score'] = (24 - self.df['scheduled_hour']) * 2 + np.random.random(len(self.df)) * 10\n",
        "            return self.df.sort_values('impact_score', ascending=False).head(top_n)\n",
        "\n",
        "        print(\"üí• Analyzing cascading impact with PageRank...\")\n",
        "\n",
        "        try:\n",
        "            if not self.graph.nodes():\n",
        "                self.build_flight_network()\n",
        "\n",
        "            if self.graph.nodes() and self.graph.edges():\n",
        "                pagerank_scores = nx.pagerank(self.graph, weight='weight')\n",
        "                self.df['impact_score'] = self.df['flight_id'].map(pagerank_scores).fillna(0)\n",
        "\n",
        "                # Normalize scores\n",
        "                if self.df['impact_score'].max() > 0:\n",
        "                    self.df['impact_score'] = (self.df['impact_score'] / self.df['impact_score'].max()) * 100\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è No connections found in flight network. Using random impact scores.\")\n",
        "                self.df['impact_score'] = np.random.random(len(self.df)) * 100\n",
        "\n",
        "            print(\"‚úÖ Top flights identified as potential 'super-spreaders' of delays.\")\n",
        "            return self.df.sort_values('impact_score', ascending=False).head(top_n)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in PageRank analysis: {e}\")\n",
        "            # Fallback to random scores\n",
        "            self.df['impact_score'] = np.random.random(len(self.df)) * 100\n",
        "            return self.df.sort_values('impact_score', ascending=False).head(top_n)"
      ],
      "metadata": {
        "id": "SGgZGgSpt93J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 6. CP-SAT SCHEDULE OPTIMIZER (NEW & ADVANCED)\n",
        "# ===============================================================================\n",
        "class CPSATScheduleOptimizer:\n",
        "    \"\"\"\n",
        "    Uses Google's CP-SAT solver to find a mathematically optimal schedule.\n",
        "    \"\"\"\n",
        "    def __init__(self, flights_df):\n",
        "        self.flights_df = flights_df.copy()\n",
        "        if len(self.flights_df) > 0:\n",
        "            self.flights_df['original_start_min'] = (self.flights_df['std'].dt.hour * 60 +\n",
        "                                                     self.flights_df['std'].dt.minute)\n",
        "\n",
        "    def optimize(self, runway_capacity=3):\n",
        "        if not ORTOOLS_AVAILABLE:\n",
        "            print(\"‚ùå OR-Tools not available. Skipping schedule optimization.\")\n",
        "            return None\n",
        "\n",
        "        print(\"üß† Optimizing schedule with CP-SAT Solver...\")\n",
        "\n",
        "        try:\n",
        "            model = cp_model.CpModel()\n",
        "            flights = self.flights_df.to_dict('records')\n",
        "\n",
        "            if not flights:\n",
        "                print(\"‚ùå No flights to optimize\")\n",
        "                return None\n",
        "\n",
        "            intervals = []\n",
        "            start_vars = []\n",
        "\n",
        "            for i, f in enumerate(flights):\n",
        "                start_var = model.NewIntVar(0, 24 * 60, f'start_{i}')\n",
        "                duration = 2  # Runway usage is 2 minutes\n",
        "                end_var = model.NewIntVar(0, 24 * 60, f'end_{i}')\n",
        "                interval = model.NewIntervalVar(start_var, duration, end_var, f'interval_{i}')\n",
        "                intervals.append(interval)\n",
        "                start_vars.append(start_var)\n",
        "\n",
        "            # Capacity constraint\n",
        "            model.AddCumulative(intervals, [1] * len(flights), runway_capacity)\n",
        "\n",
        "            # Minimize deviation from original schedule\n",
        "            total_deviation = model.NewIntVar(0, 1000000, 'total_deviation')\n",
        "            deviations = []\n",
        "            for i, f in enumerate(flights):\n",
        "                deviation = model.NewIntVar(0, 24 * 60, f'deviation_{i}')\n",
        "                model.AddAbsEquality(deviation, start_vars[i] - int(f['original_start_min']))\n",
        "                deviations.append(deviation)\n",
        "\n",
        "            model.Add(total_deviation == sum(deviations))\n",
        "            model.Minimize(total_deviation)\n",
        "\n",
        "            solver = cp_model.CpSolver()\n",
        "            solver.parameters.max_time_in_seconds = 20.0\n",
        "            status = solver.Solve(model)\n",
        "\n",
        "            if status in (cp_model.OPTIMAL, cp_model.FEASIBLE):\n",
        "                print(f\"‚úÖ Optimal schedule found! Minimized total deviation: {solver.ObjectiveValue():.0f} minutes.\")\n",
        "\n",
        "                optimized_starts = [solver.Value(s) for s in start_vars]\n",
        "                self.flights_df['optimized_start_min'] = optimized_starts\n",
        "\n",
        "                # Convert back to datetime\n",
        "                base_date = self.flights_df['std'].iloc[0].date()\n",
        "                self.flights_df['optimized_std'] = [\n",
        "                    datetime.combine(base_date, datetime.min.time()) + timedelta(minutes=int(start_min))\n",
        "                    for start_min in optimized_starts\n",
        "                ]\n",
        "\n",
        "                return self.flights_df\n",
        "            else:\n",
        "                print(\"‚ùå Could not find an optimal solution.\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in schedule optimization: {e}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "w-Qs0RlhuMuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 7. SEMANTIC NLP ASSISTANT (NEW & ADVANCED)\n",
        "# ===============================================================================\n",
        "class SemanticNLPAssistant:\n",
        "    \"\"\"\n",
        "    An NLP assistant that understands the meaning of queries using a lightweight transformer.\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.model = None\n",
        "\n",
        "        if SENTENCE_TRANSFORMERS_AVAILABLE:\n",
        "            try:\n",
        "                print(\"üß† Initializing Semantic NLP Assistant...\")\n",
        "                self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "                self.known_questions = [\n",
        "                    \"What are the busiest hours?\", \"Show airline performance.\",\n",
        "                    \"Which routes have the most delays?\", \"How can we optimize the schedule?\"\n",
        "                ]\n",
        "                self.known_embeddings = self.model.encode(self.known_questions)\n",
        "                print(\"‚úÖ NLP Assistant is ready.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error initializing NLP Assistant: {e}\")\n",
        "                self.model = None\n",
        "        else:\n",
        "            print(\"‚ùå SentenceTransformers not available. Using simple keyword matching.\")\n",
        "\n",
        "    def process_query(self, query):\n",
        "        if self.model is None:\n",
        "            # Simple keyword-based fallback\n",
        "            return self._simple_keyword_match(query)\n",
        "\n",
        "        try:\n",
        "            query_embedding = self.model.encode(query)\n",
        "\n",
        "            # Use sentence-transformers utility for cosine similarity\n",
        "            cosine_scores = util.cos_sim(query_embedding, self.known_embeddings)[0]\n",
        "            best_match_idx = np.argmax(cosine_scores)\n",
        "            best_match_score = cosine_scores[best_match_idx]\n",
        "\n",
        "            print(f\"   (Match: '{self.known_questions[best_match_idx]}', Score: {best_match_score:.2f})\")\n",
        "\n",
        "            if best_match_score > 0.5:\n",
        "                return self._get_answer(int(best_match_idx))\n",
        "            return \"I'm not sure how to answer that. Please try rephrasing.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing query: {e}\")\n",
        "            return self._simple_keyword_match(query)\n",
        "\n",
        "    def _simple_keyword_match(self, query):\n",
        "        \"\"\"Simple keyword-based matching as fallback\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if any(word in query_lower for word in ['busy', 'hour', 'traffic', 'peak']):\n",
        "            return self._get_answer(0)\n",
        "        elif any(word in query_lower for word in ['airline', 'performance', 'best', 'worst']):\n",
        "            return self._get_answer(1)\n",
        "        elif any(word in query_lower for word in ['route', 'delay', 'destination']):\n",
        "            return self._get_answer(2)\n",
        "        elif any(word in query_lower for word in ['optimize', 'improve', 'schedule']):\n",
        "            return self._get_answer(3)\n",
        "        else:\n",
        "            return \"I can help with questions about busy hours, airline performance, route delays, or schedule optimization.\"\n",
        "\n",
        "    def _get_answer(self, index):\n",
        "        try:\n",
        "            if index == 0:  # Busiest hours\n",
        "                if 'scheduled_hour' in self.df.columns:\n",
        "                    analysis = self.df.groupby('scheduled_hour')['flight_id'].count().nlargest(3)\n",
        "                    return f\"The busiest hours are:\\n{analysis.to_string()}\"\n",
        "                else:\n",
        "                    return \"Hour data not available in the dataset.\"\n",
        "\n",
        "            elif index == 1:  # Airline performance\n",
        "                if 'airline' in self.df.columns and 'arr_delay' in self.df.columns:\n",
        "                    analysis = self.df.groupby('airline')['arr_delay'].mean().sort_values()\n",
        "                    return f\"Airline performance (avg delay):\\n{analysis.round(2).to_string()}\"\n",
        "                else:\n",
        "                    return \"Airline performance data not available.\"\n",
        "\n",
        "            elif index == 2:  # Route delays\n",
        "                if 'to' in self.df.columns and 'arr_delay' in self.df.columns:\n",
        "                    analysis = self.df.groupby('to')['arr_delay'].mean().sort_values(ascending=False).head(5)\n",
        "                    return f\"Routes with most delays:\\n{analysis.round(2).to_string()}\"\n",
        "                else:\n",
        "                    return \"Route delay data not available.\"\n",
        "\n",
        "            else:\n",
        "                return \"Schedule optimization analysis is available through the CP-SAT optimizer.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error analyzing data: {e}\"\n"
      ],
      "metadata": {
        "id": "wQVkzZOtuV5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 8. MAIN EXECUTION\n",
        "# ===============================================================================\n",
        "def main():\n",
        "    print(\"=\" * 70)\n",
        "    print(\"üöÄ ADVANCED FLIGHT SCHEDULING & OPTIMIZATION SYSTEM\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    try:\n",
        "        # --- Step 1: Data Processing ---\n",
        "        print(\"\\nüìä Step 1: Data Processing\")\n",
        "        processor = FlightDataProcessor()\n",
        "        df = processor.generate_synthetic_data(n_flights=1000)\n",
        "        df = processor.engineer_features(df)\n",
        "        print(f\"‚úÖ Generated {len(df)} flight records\")\n",
        "\n",
        "        # --- Step 2: Flight Operations Simulation ---\n",
        "        print(\"\\nüé≠ Step 2: Flight Operations Simulation\")\n",
        "        simulator = FlightSimulator(processor.runway_config, processor.gate_config)\n",
        "        simulation_results = simulator.simulate_day(df)\n",
        "\n",
        "        print(\"\\nSimulation Results:\")\n",
        "        for scenario, data in simulation_results.items():\n",
        "            print(f\"  - Scenario: {scenario.replace('_', ' ').title()}\")\n",
        "            print(f\"    - Average Delay: {data['avg_delay']:.2f} mins\")\n",
        "            print(f\"    - Max Queue Length: {data['max_queue_length']:.0f} flights\")\n",
        "            print(f\"    - Total Delay: {data['total_delay'] / 60:.1f} hours\")\n",
        "\n",
        "        # --- Step 3: Predictive Analysis ---\n",
        "        print(\"\\nü§ñ Step 3: Predictive Analysis\")\n",
        "        predictor = AdvancedFlightPredictor()\n",
        "        models = predictor.train_ensemble_models(df)\n",
        "\n",
        "        if models:\n",
        "            print(f\"‚úÖ Trained {len(models)} models successfully\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Model training had issues, but continuing...\")\n",
        "\n",
        "        # --- Step 4: Cascading Impact Analysis ---\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üí• Step 4: CASCADING IMPACT ANALYSIS (GRAPH-BASED)\")\n",
        "        print(\"=\"*70)\n",
        "        impact_analyzer = GraphImpactAnalyzer(df)\n",
        "        top_disruptors = impact_analyzer.find_top_disruptors()\n",
        "        df = impact_analyzer.df\n",
        "\n",
        "        print(\"\\nTop 10 Potential Delay 'Super-Spreaders':\")\n",
        "        display_cols = ['flight_id', 'std', 'aircraft']\n",
        "        if 'impact_score' in df.columns:\n",
        "            display_cols.append('impact_score')\n",
        "        print(top_disruptors[display_cols].head(10).round(2))\n",
        "\n",
        "        # --- Step 5: Schedule Optimization ---\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üß† Step 5: SCHEDULE OPTIMIZATION (CP-SAT SOLVER)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        flights_to_optimize = df.head(50)  # Reduced for faster processing\n",
        "        optimizer = CPSATScheduleOptimizer(flights_to_optimize)\n",
        "        optimized_df = optimizer.optimize()\n",
        "\n",
        "        if optimized_df is not None:\n",
        "            print(\"\\nSample of Optimized Schedule:\")\n",
        "            opt_display_cols = ['flight_id', 'std']\n",
        "            if 'optimized_std' in optimized_df.columns:\n",
        "                opt_display_cols.append('optimized_std')\n",
        "            print(optimized_df[opt_display_cols].head())\n",
        "\n",
        "        # --- Step 6: Semantic NLP Assistant ---\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üí¨ Step 6: AI OPERATIONS ASSISTANT (SEMANTIC NLP)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        nlp_assistant = SemanticNLPAssistant(df)\n",
        "        queries = [\"Show me airport traffic patterns\", \"Which airline is best?\"]\n",
        "\n",
        "        for q in queries:\n",
        "            print(f\"\\nUser Query: '{q}'\")\n",
        "            response = nlp_assistant.process_query(q)\n",
        "            print(f\"Assistant: {response}\")\n",
        "\n",
        "        # --- Step 7: Saving Components for Dashboard ---\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üíæ Step 7: SAVING COMPONENTS FOR DASHBOARD\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            df.to_csv('flight_data_with_impact.csv', index=False)\n",
        "            print(\"‚úÖ Saved flight data with impact analysis\")\n",
        "\n",
        "            if optimized_df is not None:\n",
        "                optimized_df.to_csv('optimized_schedule.csv', index=False)\n",
        "                print(\"‚úÖ Saved optimized schedule\")\n",
        "\n",
        "            # Save model information\n",
        "            model_info = {\n",
        "                'model_trained': len(models) > 0,\n",
        "                'features': predictor.feature_columns,\n",
        "                'models_available': list(models.keys()) if models else [],\n",
        "                'total_flights': len(df),\n",
        "                'lightgbm_available': LIGHTGBM_AVAILABLE,\n",
        "                'networkx_available': NETWORKX_AVAILABLE,\n",
        "                'ortools_available': ORTOOLS_AVAILABLE,\n",
        "                'sentence_transformers_available': SENTENCE_TRANSFORMERS_AVAILABLE\n",
        "            }\n",
        "\n",
        "            with open('model_info.json', 'w') as f:\n",
        "                json.dump(model_info, f, indent=2)\n",
        "            print(\"‚úÖ Saved model information\")\n",
        "\n",
        "            # Generate summary statistics\n",
        "            summary_stats = {\n",
        "                'total_flights': len(df),\n",
        "                'avg_departure_delay': df['dep_delay'].mean(),\n",
        "                'avg_arrival_delay': df['arr_delay'].mean(),\n",
        "                'on_time_performance': (df['arr_delay'] <= 15).mean() * 100,\n",
        "                'airlines': df['airline'].unique().tolist(),\n",
        "                'destinations': df['to'].unique().tolist(),\n",
        "                'aircraft_types': df['aircraft_type'].unique().tolist()\n",
        "            }\n",
        "\n",
        "            with open('summary_stats.json', 'w') as f:\n",
        "                json.dump(summary_stats, f, indent=2, default=str)\n",
        "            print(\"‚úÖ Saved summary statistics\")\n",
        "\n",
        "            print(\"‚úÖ All components saved successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error saving files: {e}\")\n",
        "\n",
        "        # --- Final Summary ---\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üìã EXECUTION SUMMARY\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"‚úÖ Data Processing: Generated {len(df)} flights\")\n",
        "        print(f\"‚úÖ Flight Simulation: Ran {len(simulation_results)} scenarios\")\n",
        "        print(f\"‚úÖ ML Models: Trained {len(models)} models\" if models else \"‚ö†Ô∏è ML Models: Training had issues\")\n",
        "        print(f\"‚úÖ Impact Analysis: Analyzed {len(df)} flights\")\n",
        "        print(f\"‚úÖ Schedule Optimization: {'Completed' if optimized_df is not None else 'Skipped (OR-Tools unavailable)'}\")\n",
        "        print(f\"‚úÖ NLP Assistant: {'Advanced mode' if SENTENCE_TRANSFORMERS_AVAILABLE else 'Keyword mode'}\")\n",
        "\n",
        "        print(\"\\nüîß Package Availability:\")\n",
        "        print(f\"  - LightGBM: {'‚úÖ' if LIGHTGBM_AVAILABLE else '‚ùå'}\")\n",
        "        print(f\"  - NetworkX: {'‚úÖ' if NETWORKX_AVAILABLE else '‚ùå'}\")\n",
        "        print(f\"  - OR-Tools: {'‚úÖ' if ORTOOLS_AVAILABLE else '‚ùå'}\")\n",
        "        print(f\"  - SentenceTransformers: {'‚úÖ' if SENTENCE_TRANSFORMERS_AVAILABLE else '‚ùå'}\")\n",
        "\n",
        "        print(\"\\nüéâ System execution completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Critical error in main execution: {e}\")\n",
        "        print(\"üîß Please check your data and try again.\")\n",
        "\n",
        "# ===============================================================================\n",
        "# EXECUTION ENTRY POINT\n",
        "# ===============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "hvMtzQDSuerI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}